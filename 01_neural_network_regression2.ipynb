{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## neural_network_regression.ipynb\r\n",
    "## 머신러닝\r\n",
    "## 1. Supervised (Regression, Classification)\r\n",
    "## 2. Non-supervised\r\n",
    "## 3. Reinforce"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## regression 문제 해결! (특정 값인 숫자를 예측하고자는 것)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X = np.array([-7., -4., -1., 2., 5., 8., 11., 14.])  # feature"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "y = np.array([3., 6., 9., 12., 15., 18., 21., 24.]) # 라벨"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "plt.scatter(X, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2d38d355c40>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"251.846694pt\" version=\"1.1\" viewBox=\"0 0 374.562825 251.846694\" width=\"374.562825pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-21T15:36:30.115907</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 251.846694 \r\nL 374.562825 251.846694 \r\nL 374.562825 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 227.968569 \r\nL 361.725 227.968569 \r\nL 361.725 10.528569 \r\nL 26.925 10.528569 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"PathCollection_1\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m5d8652f448\" style=\"stroke:#1f77b4;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#p923c4e9301)\">\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"42.143182\" xlink:href=\"#m5d8652f448\" y=\"218.084933\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.623701\" xlink:href=\"#m5d8652f448\" y=\"189.845972\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"129.104221\" xlink:href=\"#m5d8652f448\" y=\"161.607011\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.58474\" xlink:href=\"#m5d8652f448\" y=\"133.36805\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"216.06526\" xlink:href=\"#m5d8652f448\" y=\"105.129089\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"259.545779\" xlink:href=\"#m5d8652f448\" y=\"76.890128\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"303.026299\" xlink:href=\"#m5d8652f448\" y=\"48.651167\"/>\r\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"346.506818\" xlink:href=\"#m5d8652f448\" y=\"20.412206\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mc182872fda\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"71.130195\" xlink:href=\"#mc182872fda\" y=\"227.968569\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- −5 -->\r\n      <g transform=\"translate(63.759101 242.567007)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 678 2272 \r\nL 4684 2272 \r\nL 4684 1741 \r\nL 678 1741 \r\nL 678 2272 \r\nz\r\n\" id=\"DejaVuSans-2212\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"143.597727\" xlink:href=\"#mc182872fda\" y=\"227.968569\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(140.416477 242.567007)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"216.06526\" xlink:href=\"#mc182872fda\" y=\"227.968569\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(212.88401 242.567007)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"288.532792\" xlink:href=\"#mc182872fda\" y=\"227.968569\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(282.170292 242.567007)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"361.000325\" xlink:href=\"#mc182872fda\" y=\"227.968569\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(354.637825 242.567007)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m7ea2917e54\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7ea2917e54\" y=\"199.258959\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 203.058178)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7ea2917e54\" y=\"152.194024\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 155.993243)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7ea2917e54\" y=\"105.129089\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 108.928308)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7ea2917e54\" y=\"58.064154\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 61.863373)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7ea2917e54\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 227.968569 \r\nL 26.925 10.528569 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 361.725 227.968569 \r\nL 361.725 10.528569 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 227.968569 \r\nL 361.725 227.968569 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 10.528569 \r\nL 361.725 10.528569 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p923c4e9301\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"10.528569\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델링 (modelling) : X와 y에 숨겨진 pattern(패턴)을 찾고 계산, 수식으로 표현하고 싶다!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import tensorflow as tf\r\n",
    "\r\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\r\n",
    "house_price = tf.constant([939700])\r\n",
    "house_info, house_price, house_info.shape, house_price.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>,\n",
       " TensorShape([3]),\n",
       " TensorShape([1]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 신경망 (neural network)을 활용할 때 가장 중요한 개념중에 하나가 입력 shape, 출력 shape\r\n",
    "## input shape (입력 shape) : 모델에 입력할 데이터의 shape\r\n",
    "## output shape (출력 shape) : 입력한 데이터를 모델이 처리하고 내보내는 결과의 shape\r\n",
    "## input shape, output shape를 우리가 해결하려는 문제에 따라서 항상 다르다!\r\n",
    "## 신경망은 숫자를 받아들이고, 숫자로 결과를 알려줍니다. 일반적으로 이러한 숫자들은 tensor 및 array로 표현합니다.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 입력인 X를 통해서 y를 예측하고 싶다! ==> regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "input_shape = X[0].shape\r\n",
    "output_shape = y[0].shape\r\n",
    "\r\n",
    "X[0], input_shape, y[0], output_shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-7.0, (), 3.0, ())"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TensorFlow로 모델링을 하는 과정, 즉 모델을 생성하고 학습하는 3가지 과정\r\n",
    "## 1. 모델을 create : 직접 신경망의 계층을 추가합니다 / 이전에 만들어진 모델을 가져와서 사용 (전이학습 transfer learning)\r\n",
    "## 2. 모델을 compile : 모델의 성능을 평가할 수 있는 지표 지정 (loss/metrics)하고 모델이 어떻게 개선되어야할지 정의 (optimizer)\r\n",
    "## 3. 모델을 fit : 데이터에서 패턴을 찾도록 시키는 것"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tf.random.set_seed(42)\r\n",
    "\r\n",
    "# 1. 모델을 create\r\n",
    "model = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.Dense(1)\r\n",
    "])\r\n",
    "\r\n",
    "# 2. 모델을 compile\r\n",
    "model.compile(\r\n",
    "    loss = tf.keras.losses.mae,   # mean absolute error\r\n",
    "    optimizer = tf.keras.optimizers.SGD(), # short for stochastic gradient descent\r\n",
    "    metrics = [\"mae\"]\r\n",
    ")\r\n",
    "\r\n",
    "# 3. 모델을 fit\r\n",
    "model.fit(X, y, epochs = 5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d39b3e01c0>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-7., -4., -1.,  2.,  5.,  8., 11., 14.]),\n",
       " array([ 3.,  6.,  9., 12., 15., 18., 21., 24.]))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# 4. 만들고 학습한 모델로 predict\r\n",
    "model.predict([17.0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model.predict([-10.0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-7.4006]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 학습한 모델의 결과가 좋지 않아요!\r\n",
    "## 모델을 성능을 더 좋게 만들어야 합니다.\r\n",
    "## 1. 모델을 create : 계층을 추가해 준다! / 계층을 구성하는 neuron을 추가 / actionvation function (활성화 함수)를 바꿔본다\r\n",
    "## 2. 모델을 compile : optimization function (최적화 함수)를 바꿔본다 / 최적화 함수의 learning rate를 변경\r\n",
    "## 3. 모델을 fit : 더 많이 공부, 즉 학습 epoch를 늘린다! => 시간이 늘어난다 / 학습하는 데이터를 더 많이 준다!\r\n",
    "\r\n",
    "## 계층을 추가해 준다! / 계층을 구성하는 neuron을 추가 / 최적화 함수의 learning rate를 변경\r\n",
    "## 지금까지 모델을 개선하기 위해서 설명한 위의 내용들은 개발자가 직접 변경할 수 있다!\r\n",
    "## hyperparameter라고 합니다.\r\n",
    "## hyperparameter를 우리가 직접 수정하는 그 과정 => hyperparameter tuning!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "tf.random.set_seed(42)\r\n",
    "\r\n",
    "# 1. 모델을 create\r\n",
    "model = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.Dense(1)\r\n",
    "])\r\n",
    "\r\n",
    "# 2. 모델을 compile\r\n",
    "model.compile(\r\n",
    "    loss = tf.keras.losses.mae,   # mean absolute error\r\n",
    "    optimizer = tf.keras.optimizers.SGD(), # short for stochastic gradient descent\r\n",
    "    metrics = [\"mae\"]\r\n",
    ")\r\n",
    "\r\n",
    "# 3. 모델을 fit\r\n",
    "model.fit(X, y, epochs = 200)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6498 - mae: 9.6498\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5173 - mae: 9.5173\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3848 - mae: 9.3848\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2523 - mae: 9.2523\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.1198 - mae: 9.1198\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9873 - mae: 8.9873\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7223 - mae: 8.7223\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5898 - mae: 8.5898\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4573 - mae: 8.4573\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3248 - mae: 8.3248\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1923 - mae: 8.1923\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0598 - mae: 8.0598\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7948 - mae: 7.7948\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6623 - mae: 7.6623\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5298 - mae: 7.5298\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3973 - mae: 7.3973\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2648 - mae: 7.2648\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1963 - mae: 7.1963\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1738 - mae: 7.1738\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8813 - mae: 6.8813\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8756 - mae: 6.8756\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8700 - mae: 6.8700\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8644 - mae: 6.8644\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8588 - mae: 6.8588\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8531 - mae: 6.8531\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8475 - mae: 6.8475\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8419 - mae: 6.8419\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8363 - mae: 6.8363\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8306 - mae: 6.8306\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8250 - mae: 6.8250\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8194 - mae: 6.8194\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8138 - mae: 6.8138\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8081 - mae: 6.8081\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8025 - mae: 6.8025\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7969 - mae: 6.7969\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7913 - mae: 6.7913\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7856 - mae: 6.7856\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7800 - mae: 6.7800\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7744 - mae: 6.7744\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7688 - mae: 6.7688\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7631 - mae: 6.7631\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7575 - mae: 6.7575\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7519 - mae: 6.7519\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7463 - mae: 6.7463\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7406 - mae: 6.7406\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7350 - mae: 6.7350\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7294 - mae: 6.7294\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7238 - mae: 6.7238\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7181 - mae: 6.7181\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7125 - mae: 6.7125\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7069 - mae: 6.7069\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7013 - mae: 6.7013\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6956 - mae: 6.6956\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6900 - mae: 6.6900\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6844 - mae: 6.6844\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6788 - mae: 6.6788\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6731 - mae: 6.6731\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6675 - mae: 6.6675\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6619 - mae: 6.6619\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6562 - mae: 6.6562\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6506 - mae: 6.6506\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6450 - mae: 6.6450\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6394 - mae: 6.6394\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6337 - mae: 6.6337\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6281 - mae: 6.6281\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6225 - mae: 6.6225\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6169 - mae: 6.6169\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6112 - mae: 6.6112\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6056 - mae: 6.6056\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6000 - mae: 6.6000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5944 - mae: 6.5944\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5887 - mae: 6.5887\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5831 - mae: 6.5831\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5775 - mae: 6.5775\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5719 - mae: 6.5719\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5662 - mae: 6.5662\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5606 - mae: 6.5606\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5550 - mae: 6.5550\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5494 - mae: 6.5494\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.5437 - mae: 6.5437\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5381 - mae: 6.5381\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5325 - mae: 6.5325\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5269 - mae: 6.5269\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5212 - mae: 6.5212\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5156 - mae: 6.5156\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5100 - mae: 6.5100\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5044 - mae: 6.5044\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4987 - mae: 6.4987\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4931 - mae: 6.4931\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4875 - mae: 6.4875\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4819 - mae: 6.4819\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4762 - mae: 6.4762\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4706 - mae: 6.4706\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4650 - mae: 6.4650\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4594 - mae: 6.4594\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4537 - mae: 6.4537\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4481 - mae: 6.4481\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4425 - mae: 6.4425\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4369 - mae: 6.4369\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4312 - mae: 6.4312\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4256 - mae: 6.4256\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4200 - mae: 6.4200\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4144 - mae: 6.4144\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4087 - mae: 6.4087\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4031 - mae: 6.4031\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3975 - mae: 6.3975\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3919 - mae: 6.3919\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3862 - mae: 6.3862\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3806 - mae: 6.3806\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3750 - mae: 6.3750\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3694 - mae: 6.3694\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3637 - mae: 6.3637\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3581 - mae: 6.3581\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3525 - mae: 6.3525\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3469 - mae: 6.3469\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3412 - mae: 6.3412\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3356 - mae: 6.3356\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3300 - mae: 6.3300\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3244 - mae: 6.3244\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3187 - mae: 6.3187\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d39b655f10>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X, y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-7., -4., -1.,  2.,  5.,  8., 11., 14.]),\n",
       " array([ 3.,  6.,  9., 12., 15., 18., 21., 24.]))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model.predict([17.0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[30.908516]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 평가 (Evaluating a model)\r\n",
    "## 일반적인 신경망을 만드는 과정\r\n",
    "## 모델 생성 -> 모델 평가 -> 평가를 기반으로 모델 수정 -> 모델 평가 -> 평가를 기반으로 모델 수정 ... 반복\r\n",
    "## 수정이라는 표현은 모델을 다시 만든다라고 하기 보다 기존 설정을 변경한다라는 의미\r\n",
    "## 시각화로 모델을 쉽고 직관적으로 평가를 하려합니다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "6f1725972fb909c3465f7b599747d17a3bf3d0967665364aa11ce66153952e4a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}